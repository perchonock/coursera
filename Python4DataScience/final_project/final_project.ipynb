{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might help if the notebook kernel dies\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_set = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.loc[:, train_set.columns != 'label'] \n",
    "X_test = test_set.loc[:, test_set.columns != 'label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['label']\n",
    "y_test = test_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming labels into on-hot vectors\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'log_regression'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = tf.keras.models.Sequential()\n",
    "lr_model.add(tf.keras.layers.Dense(num_classes, activation='softmax', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 1.4225 - acc: 0.5668 - val_loss: 1.0401 - val_acc: 0.6831\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.9367 - acc: 0.7053 - val_loss: 0.8601 - val_acc: 0.7233\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.8171 - acc: 0.7384 - val_loss: 0.7807 - val_acc: 0.7524\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.7547 - acc: 0.7579 - val_loss: 0.7319 - val_acc: 0.7684\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.7137 - acc: 0.7716 - val_loss: 0.6978 - val_acc: 0.7780\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.6841 - acc: 0.7800 - val_loss: 0.6725 - val_acc: 0.7852\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.6612 - acc: 0.7872 - val_loss: 0.6525 - val_acc: 0.7906\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.6428 - acc: 0.7931 - val_loss: 0.6358 - val_acc: 0.7950\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.6275 - acc: 0.7972 - val_loss: 0.6231 - val_acc: 0.7994\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.6144 - acc: 0.8011 - val_loss: 0.6106 - val_acc: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10d53b978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6105979048728943\n",
      "Test accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = lr_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from the 5.2.6 lecture but without drop-out\n",
    "model_name = 'NN_1'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "NN_model = tf.keras.models.Sequential()\n",
    "NN_model.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "NN_model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.5092 - acc: 0.8208 - val_loss: 0.3789 - val_acc: 0.8655\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.3605 - acc: 0.8693 - val_loss: 0.3423 - val_acc: 0.8762\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.3216 - acc: 0.8824 - val_loss: 0.3397 - val_acc: 0.8737\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.3000 - acc: 0.8888 - val_loss: 0.3293 - val_acc: 0.8780\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.2801 - acc: 0.8963 - val_loss: 0.3045 - val_acc: 0.8899\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.2624 - acc: 0.9036 - val_loss: 0.2971 - val_acc: 0.8923\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2517 - acc: 0.9072 - val_loss: 0.3058 - val_acc: 0.8905\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.2412 - acc: 0.9097 - val_loss: 0.2983 - val_acc: 0.8953\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.2253 - acc: 0.9156 - val_loss: 0.3101 - val_acc: 0.8880\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.2206 - acc: 0.9175 - val_loss: 0.3218 - val_acc: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3df75e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "NN_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3217536784052849\n",
      "Test accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding drop-out\n",
    "model_name = 'NN_2'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "NN_model2 = tf.keras.models.Sequential()\n",
    "NN_model2.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "NN_model2.add(tf.keras.layers.Dropout(0.2))\n",
    "NN_model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "NN_model2.add(tf.keras.layers.Dropout(0.2))\n",
    "NN_model2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.5549 - acc: 0.8020 - val_loss: 0.3898 - val_acc: 0.8549\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.3846 - acc: 0.8606 - val_loss: 0.3526 - val_acc: 0.8754\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.3543 - acc: 0.8707 - val_loss: 0.3285 - val_acc: 0.8825\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.3342 - acc: 0.8761 - val_loss: 0.3213 - val_acc: 0.8811\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.3115 - acc: 0.8846 - val_loss: 0.3195 - val_acc: 0.8814\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.3004 - acc: 0.8871 - val_loss: 0.3105 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.2891 - acc: 0.8932 - val_loss: 0.2919 - val_acc: 0.8912\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.2800 - acc: 0.8957 - val_loss: 0.2990 - val_acc: 0.8884\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.2705 - acc: 0.9002 - val_loss: 0.2916 - val_acc: 0.8929\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.2614 - acc: 0.9016 - val_loss: 0.2847 - val_acc: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3dcceb70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "NN_model2.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.284724221265316\n",
      "Test accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the number of neurons\n",
    "model_name = 'NN_3'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "NN_model3 = tf.keras.models.Sequential()\n",
    "NN_model3.add(tf.keras.layers.Dense(1000, activation='relu', input_shape=(784,)))\n",
    "NN_model3.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "NN_model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.4941 - acc: 0.8246 - val_loss: 0.3677 - val_acc: 0.8686\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.3522 - acc: 0.8712 - val_loss: 0.3363 - val_acc: 0.8770\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 28s 469us/step - loss: 0.3138 - acc: 0.8854 - val_loss: 0.3285 - val_acc: 0.8798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.2900 - acc: 0.8932 - val_loss: 0.3092 - val_acc: 0.8845\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.2738 - acc: 0.8975 - val_loss: 0.2986 - val_acc: 0.8898\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 378us/step - loss: 0.2581 - acc: 0.9035 - val_loss: 0.2880 - val_acc: 0.8941\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.2411 - acc: 0.9094 - val_loss: 0.2970 - val_acc: 0.8925\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 21s 358us/step - loss: 0.2351 - acc: 0.9108 - val_loss: 0.2888 - val_acc: 0.8928\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.2240 - acc: 0.9149 - val_loss: 0.2949 - val_acc: 0.8943\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.2092 - acc: 0.9214 - val_loss: 0.3201 - val_acc: 0.8885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb4c995160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model3.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "NN_model3.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3200952651798725\n",
      "Test accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing optimizer to Adadelta\n",
    "model_name = 'NN_4'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "NN_model4 = tf.keras.models.Sequential()\n",
    "NN_model4.add(tf.keras.layers.Dense(1000, activation='relu', input_shape=(784,)))\n",
    "NN_model4.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "NN_model4.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 29s 486us/step - loss: 0.6239 - acc: 0.7728 - val_loss: 0.4853 - val_acc: 0.8218\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.4169 - acc: 0.8468 - val_loss: 0.5136 - val_acc: 0.8119\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.3722 - acc: 0.8621 - val_loss: 0.3948 - val_acc: 0.8487\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 30s 495us/step - loss: 0.3344 - acc: 0.8754 - val_loss: 0.3569 - val_acc: 0.8652\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 29s 477us/step - loss: 0.3136 - acc: 0.8824 - val_loss: 0.3451 - val_acc: 0.8751\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.2962 - acc: 0.8880 - val_loss: 0.3719 - val_acc: 0.8600\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2762 - acc: 0.8964 - val_loss: 0.3348 - val_acc: 0.8759\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.2650 - acc: 0.9009 - val_loss: 0.3348 - val_acc: 0.8685\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.2500 - acc: 0.9045 - val_loss: 0.3302 - val_acc: 0.8792\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 28s 470us/step - loss: 0.2386 - acc: 0.9094 - val_loss: 0.3292 - val_acc: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb4cf53c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model4.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "NN_model4.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32924373329877854\n",
      "Test accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one more layer (optimizer = Adam as it performs better)\n",
    "model_name = 'NN_5'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "NN_model5 = tf.keras.models.Sequential()\n",
    "NN_model5.add(tf.keras.layers.Dense(1000, activation='relu', input_shape=(784,)))\n",
    "NN_model5.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "NN_model5.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "NN_model5.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 34s 568us/step - loss: 0.4973 - acc: 0.8196 - val_loss: 0.4186 - val_acc: 0.8478\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 33s 548us/step - loss: 0.3497 - acc: 0.8728 - val_loss: 0.3553 - val_acc: 0.8719\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 0.3186 - acc: 0.8830 - val_loss: 0.3318 - val_acc: 0.8795\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 32s 541us/step - loss: 0.2924 - acc: 0.8916 - val_loss: 0.3124 - val_acc: 0.8828\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.2708 - acc: 0.8972 - val_loss: 0.3088 - val_acc: 0.8881\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.2587 - acc: 0.9026 - val_loss: 0.3152 - val_acc: 0.8830\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 33s 556us/step - loss: 0.2441 - acc: 0.9064 - val_loss: 0.3019 - val_acc: 0.8882\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 34s 564us/step - loss: 0.2365 - acc: 0.9102 - val_loss: 0.2956 - val_acc: 0.8917\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.2254 - acc: 0.9133 - val_loss: 0.3034 - val_acc: 0.8933\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.2198 - acc: 0.9151 - val_loss: 0.3003 - val_acc: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3d2c8908>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model5.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "NN_model5.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3003028739333153\n",
      "Test accuracy: 0.8955\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = NN_model5.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itrechyokas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/itrechyokas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "CNN_X_train = X_train.as_matrix()\n",
    "CNN_X_test = X_test.as_matrix()\n",
    "CNN_X_train = CNN_X_train.reshape(60000, 28, 28, 1)\n",
    "CNN_X_test = CNN_X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from task 5.2\n",
    "model_name = 'CNN_1'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model = tf.keras.models.Sequential()\n",
    "CNN_model.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "CNN_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "CNN_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model.add(tf.keras.layers.Flatten())\n",
    "CNN_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 44s 738us/step - loss: 0.7301 - acc: 0.7291 - val_loss: 0.5906 - val_acc: 0.7742\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 48s 792us/step - loss: 0.4289 - acc: 0.8428 - val_loss: 0.4161 - val_acc: 0.8457\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.3662 - acc: 0.8674 - val_loss: 0.3694 - val_acc: 0.8602\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 45s 751us/step - loss: 0.3291 - acc: 0.8789 - val_loss: 0.3502 - val_acc: 0.8743\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 46s 759us/step - loss: 0.3060 - acc: 0.8877 - val_loss: 0.3633 - val_acc: 0.8638\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 45s 748us/step - loss: 0.2873 - acc: 0.8953 - val_loss: 0.3380 - val_acc: 0.8728\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 43s 723us/step - loss: 0.2727 - acc: 0.9009 - val_loss: 0.3096 - val_acc: 0.8864\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 43s 719us/step - loss: 0.2583 - acc: 0.9067 - val_loss: 0.2880 - val_acc: 0.8970\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 43s 724us/step - loss: 0.2457 - acc: 0.9111 - val_loss: 0.2697 - val_acc: 0.9041\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 0.2355 - acc: 0.9132 - val_loss: 0.2827 - val_acc: 0.8977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb502dbc18>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2826873733639717\n",
      "Test accuracy: 0.8977\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing kernel size to 4\n",
    "model_name = 'CNN_2'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model2 = tf.keras.models.Sequential()\n",
    "CNN_model2.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=(28,28,1)))\n",
    "CNN_model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model2.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(4,4), activation='relu'))\n",
    "CNN_model2.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model2.add(tf.keras.layers.Flatten())\n",
    "CNN_model2.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model2.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 48s 798us/step - loss: 0.7643 - acc: 0.7180 - val_loss: 0.5151 - val_acc: 0.8102\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 646us/step - loss: 0.4605 - acc: 0.8311 - val_loss: 0.4759 - val_acc: 0.8289\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 41s 690us/step - loss: 0.3885 - acc: 0.8586 - val_loss: 0.4183 - val_acc: 0.8451\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 41s 688us/step - loss: 0.3487 - acc: 0.8742 - val_loss: 0.3353 - val_acc: 0.8759\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 41s 691us/step - loss: 0.3192 - acc: 0.8820 - val_loss: 0.3525 - val_acc: 0.8711\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 41s 684us/step - loss: 0.3008 - acc: 0.8906 - val_loss: 0.3318 - val_acc: 0.8774\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 41s 689us/step - loss: 0.2824 - acc: 0.8970 - val_loss: 0.3019 - val_acc: 0.8937\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 41s 687us/step - loss: 0.2669 - acc: 0.9024 - val_loss: 0.3014 - val_acc: 0.8886\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 41s 683us/step - loss: 0.2537 - acc: 0.9065 - val_loss: 0.2996 - val_acc: 0.8919\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 41s 683us/step - loss: 0.2410 - acc: 0.9111 - val_loss: 0.3194 - val_acc: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb4f027860>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model2.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2826873733639717\n",
      "Test accuracy: 0.8977\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the number of filters\n",
    "model_name = 'CNN_3'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model3 = tf.keras.models.Sequential()\n",
    "CNN_model3.add(tf.keras.layers.Convolution2D(filters=3, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "CNN_model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model3.add(tf.keras.layers.Convolution2D(filters=3, kernel_size=(3,3), activation='relu'))\n",
    "CNN_model3.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model3.add(tf.keras.layers.Flatten())\n",
    "CNN_model3.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model3.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 1.0219 - acc: 0.6242 - val_loss: 0.7128 - val_acc: 0.7437\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.6326 - acc: 0.7604 - val_loss: 0.5983 - val_acc: 0.7735\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.5605 - acc: 0.7884 - val_loss: 0.5382 - val_acc: 0.8009\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.5257 - acc: 0.8040 - val_loss: 0.5075 - val_acc: 0.8122\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.5036 - acc: 0.8120 - val_loss: 0.4954 - val_acc: 0.8183\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.4855 - acc: 0.8205 - val_loss: 0.4876 - val_acc: 0.8150\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.4743 - acc: 0.8240 - val_loss: 0.4816 - val_acc: 0.8178\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.4615 - acc: 0.8286 - val_loss: 0.4833 - val_acc: 0.8181\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.4519 - acc: 0.8346 - val_loss: 0.4653 - val_acc: 0.8249\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.4431 - acc: 0.8377 - val_loss: 0.4577 - val_acc: 0.8343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb911fbd30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model3.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model3.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4576930235385895\n",
      "Test accuracy: 0.8343\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model3.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing optimizer from Adadelta to Adam\n",
    "model_name = 'CNN_4'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model4 = tf.keras.models.Sequential()\n",
    "CNN_model4.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "CNN_model4.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model4.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "CNN_model4.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model4.add(tf.keras.layers.Flatten())\n",
    "CNN_model4.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model4.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.6791 - acc: 0.7634 - val_loss: 0.4264 - val_acc: 0.8525\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 43s 713us/step - loss: 0.3974 - acc: 0.8582 - val_loss: 0.3712 - val_acc: 0.8693\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 44s 735us/step - loss: 0.3505 - acc: 0.8763 - val_loss: 0.3304 - val_acc: 0.8824\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 43s 718us/step - loss: 0.3168 - acc: 0.8864 - val_loss: 0.3004 - val_acc: 0.8922\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 43s 715us/step - loss: 0.2973 - acc: 0.8931 - val_loss: 0.2871 - val_acc: 0.8956\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 43s 711us/step - loss: 0.2813 - acc: 0.8979 - val_loss: 0.2892 - val_acc: 0.8943\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 43s 712us/step - loss: 0.2630 - acc: 0.9058 - val_loss: 0.2774 - val_acc: 0.9023\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 43s 722us/step - loss: 0.2520 - acc: 0.9083 - val_loss: 0.2624 - val_acc: 0.9057\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 41s 679us/step - loss: 0.2401 - acc: 0.9132 - val_loss: 0.2645 - val_acc: 0.9027\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 41s 678us/step - loss: 0.2290 - acc: 0.9168 - val_loss: 0.2571 - val_acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb94286eb8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model4.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model4.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2571335742354393\n",
      "Test accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model4.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2 more layers (also added padding as without it I got 'Negative dimension size...' error)\n",
    "model_name = 'CNN_5'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model5 = tf.keras.models.Sequential()\n",
    "CNN_model5.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "CNN_model5.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model5.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model5.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model5.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model5.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model5.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model5.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model5.add(tf.keras.layers.Flatten())\n",
    "CNN_model5.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model5.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.7308 - acc: 0.7403 - val_loss: 0.4515 - val_acc: 0.8442\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.4007 - acc: 0.8556 - val_loss: 0.3852 - val_acc: 0.8587\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.3374 - acc: 0.8794 - val_loss: 0.3165 - val_acc: 0.8859\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.3077 - acc: 0.8884 - val_loss: 0.3097 - val_acc: 0.8908\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.2848 - acc: 0.8970 - val_loss: 0.2935 - val_acc: 0.8934\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.2663 - acc: 0.9040 - val_loss: 0.2564 - val_acc: 0.9057\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.2529 - acc: 0.9077 - val_loss: 0.2482 - val_acc: 0.9097\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.2382 - acc: 0.9132 - val_loss: 0.2455 - val_acc: 0.9123\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.2211 - acc: 0.9205 - val_loss: 0.2293 - val_acc: 0.9155\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.2150 - acc: 0.9206 - val_loss: 0.2328 - val_acc: 0.9157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb949cdcc0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model5.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model5.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23282040613889693\n",
      "Test accuracy: 0.9157\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model5.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding batch mnormalization after each convolution layer\n",
    "model_name = 'CNN_6'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model6 = tf.keras.models.Sequential()\n",
    "CNN_model6.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "CNN_model6.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model6.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model6.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model6.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model6.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model6.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model6.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model6.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model6.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model6.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model6.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model6.add(tf.keras.layers.Flatten())\n",
    "CNN_model6.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model6.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4476 - acc: 0.8442 - val_loss: 2.5112 - val_acc: 0.1353\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.2673 - acc: 0.9026 - val_loss: 0.7412 - val_acc: 0.7289\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.2271 - acc: 0.9177 - val_loss: 0.2781 - val_acc: 0.8955\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.1962 - acc: 0.9282 - val_loss: 0.2681 - val_acc: 0.9092\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.1750 - acc: 0.9358 - val_loss: 0.2262 - val_acc: 0.9184\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.1573 - acc: 0.9414 - val_loss: 0.2362 - val_acc: 0.9175\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.1410 - acc: 0.9475 - val_loss: 0.2442 - val_acc: 0.9184\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.1259 - acc: 0.9534 - val_loss: 0.2736 - val_acc: 0.9084\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.1133 - acc: 0.9587 - val_loss: 0.2710 - val_acc: 0.9123\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0988 - acc: 0.9638 - val_loss: 0.3216 - val_acc: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb938d7d30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model6.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model6.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3215744598180056\n",
      "Test accuracy: 0.8975\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model6.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding drop-out after each max pooling layer\n",
    "model_name = 'CNN_7'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model7 = tf.keras.models.Sequential()\n",
    "CNN_model7.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "CNN_model7.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model7.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model7.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "CNN_model7.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model7.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model7.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model7.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "CNN_model7.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model7.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model7.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model7.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "CNN_model7.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model7.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model7.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model7.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "CNN_model7.add(tf.keras.layers.Flatten())\n",
    "CNN_model7.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model7.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 153s 3ms/step - loss: 0.6845 - acc: 0.7492 - val_loss: 2.8329 - val_acc: 0.1619\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.4004 - acc: 0.8519 - val_loss: 0.6462 - val_acc: 0.7597\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.3396 - acc: 0.8755 - val_loss: 0.3317 - val_acc: 0.8738\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.3061 - acc: 0.8879 - val_loss: 0.2665 - val_acc: 0.9025\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.2844 - acc: 0.8967 - val_loss: 0.4018 - val_acc: 0.8621\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.2727 - acc: 0.9004 - val_loss: 0.2368 - val_acc: 0.9115\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 155s 3ms/step - loss: 0.2606 - acc: 0.9042 - val_loss: 0.2156 - val_acc: 0.9187\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2492 - acc: 0.9088 - val_loss: 0.2146 - val_acc: 0.9206\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2421 - acc: 0.9113 - val_loss: 0.2094 - val_acc: 0.9224\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2327 - acc: 0.9136 - val_loss: 0.2014 - val_acc: 0.9253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb9e5831d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model7.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model7.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.20137879286408425\n",
      "Test accuracy: 0.9253\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model7.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried batch normalization after fully connected layer\n",
    "model_name = 'CNN_8'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}')\n",
    "\n",
    "CNN_model8 = tf.keras.models.Sequential()\n",
    "CNN_model8.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "CNN_model8.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model8.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model8.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model8.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model8.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model8.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', ))\n",
    "CNN_model8.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "CNN_model8.add(tf.keras.layers.Flatten())\n",
    "CNN_model8.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "CNN_model8.add(tf.keras.layers.BatchNormalization())\n",
    "CNN_model8.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.5009 - acc: 0.8308 - val_loss: 0.8779 - val_acc: 0.8782\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2961 - acc: 0.8955 - val_loss: 0.3617 - val_acc: 0.8822\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2493 - acc: 0.9110 - val_loss: 0.5698 - val_acc: 0.8176\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2194 - acc: 0.9209 - val_loss: 0.3268 - val_acc: 0.8819\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1991 - acc: 0.9292 - val_loss: 0.3324 - val_acc: 0.8849\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1812 - acc: 0.9349 - val_loss: 0.2820 - val_acc: 0.9043\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1643 - acc: 0.9403 - val_loss: 0.3860 - val_acc: 0.8859\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1506 - acc: 0.9462 - val_loss: 0.2880 - val_acc: 0.9059\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1363 - acc: 0.9511 - val_loss: 0.2772 - val_acc: 0.9100\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1247 - acc: 0.9555 - val_loss: 0.3446 - val_acc: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xba59c8f28>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model8.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "CNN_model8.fit(\n",
    "    CNN_X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(CNN_X_test , y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.34462651263177396\n",
      "Test accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNN_model8.evaluate(CNN_X_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model is CNN_7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
