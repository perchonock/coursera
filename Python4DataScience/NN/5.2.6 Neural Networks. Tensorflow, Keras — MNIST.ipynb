{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c4b70d9b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)\n",
    "\n",
    "image = mnist.train.images[7].reshape([28, 28]);\n",
    "plt.gray()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[7].shape)\n",
    "print(mnist.train.labels[7].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.37254903 0.8862746  0.9921569  0.9921569\n",
      " 0.8862746  0.         0.         0.36078432 0.0509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01960784 0.29803923\n",
      " 0.97647065 0.9921569  0.9921569  0.9921569  0.8862746  0.\n",
      " 0.41176474 0.9843138  0.854902   0.34117648 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[7][150:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "num_input = 784 # 28 x 28\n",
    "num_classes = 10\n",
    "\n",
    "X = tf.placeholder('float', [None, num_input])\n",
    "Y = tf.placeholder('float', [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'output': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'output': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    output_layer = tf.matmul(layer_2, weights['output']) + biases['output']\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = network(X)\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=logits, labels=Y\n",
    "    )\n",
    ")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "#         sess.run(train, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "#         if epoch % 50 == 0:\n",
    "#             train_accuracy = sess.run(\n",
    "#                 accuracy, \n",
    "#                 feed_dict={\n",
    "#                     X: mnist.train.images,\n",
    "#                     Y: mnist.train.labels\n",
    "#                 }\n",
    "#             )\n",
    "            \n",
    "#             print('Epoch #{}: train accuracy = {}'.format(epoch, train_accuracy))\n",
    "\n",
    "#     print('Test accuracy = {}'.format(\n",
    "#         sess.run(\n",
    "#             accuracy,\n",
    "#             feed_dict={\n",
    "#                 X: mnist.test.images,\n",
    "#                 Y: mnist.test.labels\n",
    "#             }\n",
    "#         )\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 20s 341us/step - loss: 0.2523 - acc: 0.9245 - val_loss: 0.1174 - val_acc: 0.9629\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.1018 - acc: 0.9684 - val_loss: 0.0860 - val_acc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "_ = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08596293197441846\n",
      "Test accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
